from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import os
import shutil

load_dotenv()

# === [å…³é”®] è®¾ç½®å›½å†…é•œåƒ ===
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# è·¯å¾„é…ç½®
PERSIST_DIR = "./chroma_db"
DATA_PATH = "./data"  # <--- è¯·ç¡®ä¿ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºäº†è¿™ä¸ªæ–‡ä»¶å¤¹ï¼

# 1. æ¸…ç†æ—§æ•°æ®åº“
if os.path.exists(PERSIST_DIR):
    shutil.rmtree(PERSIST_DIR)
    print(f"ğŸ§¹ Cleaned up old database at {PERSIST_DIR}")

# 2. åŠ è½½æ•°æ® (Loader)
print(f"ğŸ“‚ Loading documents from {DATA_PATH}...")

documents = []

# æ£€æŸ¥ data ç›®å½•æ˜¯å¦å­˜åœ¨
if not os.path.exists(DATA_PATH):
    os.makedirs(DATA_PATH)
    print(f"âš ï¸ Created missing directory: {DATA_PATH}. Please put some files in it!")
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œé˜²æ­¢æŠ¥é”™
    with open(os.path.join(DATA_PATH, "demo.txt"), "w", encoding="utf-8") as f:
        f.write("é¡¹ç›®è¿›åº¦ï¼šRAG æ£€ç´¢æ¨¡å—çš„å‘é‡å¬å›ç‡å·²ä¼˜åŒ–è‡³ 85%ï¼Œç›®å‰æ­£åœ¨è°ƒè¯•é‡æ’åº(Rerank)æ¨¡å‹ã€‚\n")
        f.write("ä¼šè®®å®‰æ’ï¼šå‘¨ä¸€ä¸Šåˆçš„æ¼”ç¤ºé‡ç‚¹æ˜¯å±•ç¤º System 2 æ…¢æ€è€ƒé€»è¾‘å’Œ Multi-Agent åä½œæµç¨‹ã€‚")

# åŠ è½½ TXT æ–‡ä»¶
txt_loader = DirectoryLoader(DATA_PATH, glob="**/*.txt", loader_cls=TextLoader)
documents.extend(txt_loader.load())

# åŠ è½½ PDF æ–‡ä»¶ (å¦‚æœä½ æ”¾å…¥äº† PDF)
pdf_loader = DirectoryLoader(DATA_PATH, glob="**/*.pdf", loader_cls=PyPDFLoader)
documents.extend(pdf_loader.load())

print(f"ğŸ“„ Loaded {len(documents)} source files.")

# 3. æ–‡æœ¬åˆ‡åˆ† (Splitter) - â­ï¸ è¿™æ˜¯ RAG çš„æ ¸å¿ƒæŠ€æœ¯ç‚¹
# ä¸ºä»€ä¹ˆåˆ‡åˆ†ï¼Ÿå› ä¸º Embedding æ¨¡å‹ä¸€æ¬¡åªèƒ½å¤„ç†æœ‰é™é•¿åº¦ï¼ˆæ¯”å¦‚512ä¸ªå­—ï¼‰ï¼Œ
# è€Œä¸”åˆ‡çŸ­ä¸€ç‚¹ï¼Œæœç´¢ä¼šæ›´ç²¾å‡†ã€‚
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,      # æ¯ä¸ªåˆ‡ç‰‡çº¦ 500 å­—ç¬¦
    chunk_overlap=50,    # åˆ‡ç‰‡ä¹‹é—´é‡å  50 å­—ç¬¦ï¼ˆé˜²æ­¢ä¸Šä¸‹æ–‡æ–­è£‚ï¼‰
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
)

split_docs = text_splitter.split_documents(documents)
print(f"âœ‚ï¸  Split into {len(split_docs)} chunks.")

# 4. åˆå§‹åŒ–æ¨¡å‹ (Embedding)
print(f"ğŸš€ Loading Embedding Model (Local BGE)...")
model_name = "BAAI/bge-small-zh-v1.5"
model_kwargs = {'device': 'cpu', 'trust_remote_code': True}
encode_kwargs = {'normalize_embeddings': True}

embedding_model = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

# 5. å‘é‡åŒ–å¹¶å­˜å‚¨ (Vector Store)
print(f"ğŸš€ Vectorizing & Saving...")

vector_db = Chroma.from_documents(
    documents=split_docs, # æ³¨æ„ï¼šè¿™é‡Œå­˜å…¥çš„æ˜¯åˆ‡åˆ†åçš„ split_docs
    embedding=embedding_model, 
    persist_directory=PERSIST_DIR,
    collection_name="project_knowledge"
)

print(f"âœ… Knowledge Base Updated! Saved to {PERSIST_DIR}")